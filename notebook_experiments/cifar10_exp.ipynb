{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "06c73d0c-053f-4ab4-bdec-8a20544bf42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import ConcatDataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "231dbea1-4658-47d1-a0c8-7a2845fdbac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "37972552-e50c-4cae-ae44-28adbccb978a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_data(data_x, data_y, num_points_per_task, total_task=10, shift=1):\n",
    "    x = data_x.copy()\n",
    "    y = data_y.copy()\n",
    "    idx = [np.where(data_y == u)[0] for u in np.unique(data_y)]\n",
    "\n",
    "    batch_per_task = 5000 // num_points_per_task\n",
    "    sample_per_class = num_points_per_task // total_task\n",
    "    test_data_slot = 100 // batch_per_task\n",
    "    class_per_task = 100//total_task\n",
    "    \n",
    "    for task in range(total_task):\n",
    "        for batch in range(batch_per_task):\n",
    "            for class_no in range(task * class_per_task, (task + 1) * class_per_task, 1):\n",
    "                indx = np.roll(idx[class_no], (shift - 1) * 100)\n",
    "\n",
    "                if batch == 0 and class_no == 0 and task == 0:\n",
    "                    train_x = x[\n",
    "                        indx[batch * sample_per_class : (batch + 1) * sample_per_class],\n",
    "                        :,\n",
    "                    ]\n",
    "                    train_y = y[\n",
    "                        indx[batch * sample_per_class : (batch + 1) * sample_per_class]\n",
    "                    ]\n",
    "                    test_x = x[\n",
    "                        indx[\n",
    "                            batch * test_data_slot\n",
    "                            + 500 : (batch + 1) * test_data_slot\n",
    "                            + 500\n",
    "                        ],\n",
    "                        :,\n",
    "                    ]\n",
    "                    test_y = y[\n",
    "                        indx[\n",
    "                            batch * test_data_slot\n",
    "                            + 500 : (batch + 1) * test_data_slot\n",
    "                            + 500\n",
    "                        ]\n",
    "                    ]\n",
    "                else:\n",
    "                    train_x = np.concatenate(\n",
    "                        (\n",
    "                            train_x,\n",
    "                            x[\n",
    "                                indx[\n",
    "                                    batch\n",
    "                                    * sample_per_class : (batch + 1)\n",
    "                                    * sample_per_class\n",
    "                                ],\n",
    "                                :,\n",
    "                            ],\n",
    "                        ),\n",
    "                        axis=0,\n",
    "                    )\n",
    "                    train_y = np.concatenate(\n",
    "                        (\n",
    "                            train_y,\n",
    "                            y[\n",
    "                                indx[\n",
    "                                    batch\n",
    "                                    * sample_per_class : (batch + 1)\n",
    "                                    * sample_per_class\n",
    "                                ]\n",
    "                            ],\n",
    "                        ),\n",
    "                        axis=0,\n",
    "                    )\n",
    "                    test_x = np.concatenate(\n",
    "                        (\n",
    "                            test_x,\n",
    "                            x[\n",
    "                                indx[\n",
    "                                    batch * test_data_slot\n",
    "                                    + 500 : (batch + 1) * test_data_slot\n",
    "                                    + 500\n",
    "                                ],\n",
    "                                :,\n",
    "                            ],\n",
    "                        ),\n",
    "                        axis=0,\n",
    "                    )\n",
    "                    test_y = np.concatenate(\n",
    "                        (\n",
    "                            test_y,\n",
    "                            y[\n",
    "                                indx[\n",
    "                                    batch * test_data_slot\n",
    "                                    + 500 : (batch + 1) * test_data_slot\n",
    "                                    + 500\n",
    "                                ]\n",
    "                            ],\n",
    "                        ),\n",
    "                        axis=0,\n",
    "                    )\n",
    "\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "66159d09-9db1-4270-854e-ff5d7e685f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X.copy()\n",
    "        self.y = y.copy()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "07af7a36-6c63-41a8-a020-af60485f84f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layer1 = nn.Conv2d(in_channels=3, out_channels=16,\n",
    "\t\t\tkernel_size=(3, 3))\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer2 = nn.Conv2d(in_channels=16, out_channels=32,\n",
    "\t\t\tkernel_size=(3, 3), padding='same')\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.layer3 = nn.Conv2d(in_channels=32, out_channels=64,\n",
    "\t\t\tkernel_size=(3, 3), padding='same')\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.layer4 = nn.Conv2d(in_channels=64, out_channels=128,\n",
    "\t\t\tkernel_size=(3, 3), padding='same')\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.layer5 = nn.Conv2d(in_channels=128, out_channels=254,\n",
    "\t\t\tkernel_size=(3, 3), padding='same')\n",
    "        self.bn5 = nn.BatchNorm2d(254)\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.linear1 = nn.Linear(228600, 100)\n",
    "        self.bn_linear1 = nn.BatchNorm1d(100)\n",
    "        self.linear2 = nn.Linear(100, 100)\n",
    "        self.bn_linear2 = nn.BatchNorm1d(100)\n",
    "        self.linear3 = nn.Linear(100, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.layer2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.layer3(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.layer4(x)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.layer5(x)\n",
    "        x = F.relu(self.bn5(x))\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(self.bn_linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        x = F.relu(self.bn_linear2(x))\n",
    "        x = self.linear3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "b264a4cd-8c91-4ec6-aabd-91ee71caf1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, latent_dim, output, nodes=10):\n",
    "        super(Head, self).__init__()\n",
    "        self.layer1 = nn.Linear(latent_dim, nodes)\n",
    "        self.layer2 = nn.Linear(nodes, nodes)\n",
    "        self.output = nn.Linear(nodes, output)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = self.output(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "63192ea8-9626-49f4-8903-5155792f5aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastLoss(nn.Module):\n",
    "    def __init__(self, latent_dim, margin=0.3, replay_const=1e-1):\n",
    "        super(ContrastLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.replay_const = replay_const\n",
    "\n",
    "    def forward(self, inputs, targets, inputs_replay, targets_replay):\n",
    "        dis_embedding = torch.cdist(\n",
    "                            inputs,\n",
    "                            inputs,\n",
    "                            p=2.0\n",
    "                        )\n",
    "\n",
    "\n",
    "        number_of_heads = targets.shape[1]\n",
    "        kernel_partition = torch.sum(\n",
    "                            targets.view(1,-1,number_of_heads)==targets.view(-1,1,number_of_heads),\n",
    "                            dim=2)/number_of_heads\n",
    "        \n",
    "        dis_partition = (1-kernel_partition)>1e-12\n",
    "\n",
    "        ############################################################\n",
    "        dis_embedding_replay = torch.cdist(\n",
    "                            inputs_replay,\n",
    "                            inputs_replay,\n",
    "                            p=2.0\n",
    "                        )\n",
    "        number_of_heads_replay = targets_replay.shape[1]\n",
    "        kernel_partition_replay = torch.sum(\n",
    "                            targets_replay.view(1,-1,number_of_heads_replay)==targets_replay.view(-1,1,number_of_heads_replay),\n",
    "                            dim=2)/number_of_heads_replay\n",
    "        \n",
    "        dis_partition_replay = (1-kernel_partition_replay)>1e-12\n",
    "        loss = torch.mul(\n",
    "                        kernel_partition,\n",
    "                        dis_embedding\n",
    "                    ) + torch.clamp(torch.mul(\n",
    "                        dis_partition,\n",
    "                        self.margin-dis_embedding\n",
    "                        ), 0.0)\n",
    "        \n",
    "        loss_replay = torch.mul(\n",
    "                        kernel_partition_replay,\n",
    "                        dis_embedding_replay\n",
    "                    ) + torch.clamp(torch.mul(\n",
    "                        dis_partition_replay,\n",
    "                        self.margin-dis_embedding_replay\n",
    "                        ), 0.0)\n",
    "                \n",
    "        return loss.mean() + self.replay_const*loss_replay.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "c2d27682-e0ee-433e-9b0d-762cb5fefd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = unpickle('/Users/jayantadey/contrastive_lifelong_learning/notebook_experiments/data/cifar-100-python/train')\n",
    "data_test = unpickle('/Users/jayantadey/contrastive_lifelong_learning/notebook_experiments/data/cifar-100-python/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "87959283-211f-40ac-b082-55dd35a434ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = data_train[b'data'], data_train[b'fine_labels']\n",
    "x2, y2 = data_test[b'data'], data_test[b'fine_labels']\n",
    "\n",
    "X_, y_ = np.concatenate((x1,x2)), np.concatenate((y1,y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "a79e8d11-6620-4d2d-8483-916eb13ce7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = X_.reshape(-1, 3, 32, 32).astype('float64')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "3f2a46b3-b49d-4da9-b533-a70f2f08adf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x175fee490>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.transpose(X_[0], (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "6ce76753-0e84-42d8-9a45-8fd44731f1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing 1 slot, 1 shift, 1 task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n",
      "[E thread_pool.cpp:112] Exception in thread pool task: mutex lock failed: Invalid argument\n"
     ]
    }
   ],
   "source": [
    "slots = 10\n",
    "shifts = 6\n",
    "batch_size = 32\n",
    "num_points_per_task = 500\n",
    "total_task = 10\n",
    "latent_dim = 5\n",
    "epoch_per_task_encoder = 100\n",
    "epoch_per_task_head = 200\n",
    "learning_rate_encoder = 3e-4\n",
    "learning_rate_head = 5e-2\n",
    "margin = 4.5\n",
    "replay_const = 7e-2\n",
    "\n",
    "for shift in range(shifts):\n",
    "    train_x, train_y, test_x, test_y = cross_val_data(X_, y_, num_points_per_task, total_task=total_task, shift=shift)\n",
    "    for slot in range(slots):\n",
    "        X_replay = []\n",
    "        y_replay = []\n",
    "        single_accuracies = []\n",
    "        accuracies = []\n",
    "        total_task_seen = 0\n",
    "        heads = {}\n",
    "        heads_single = {}\n",
    "        encoder = Encoder(latent_dim=latent_dim)\n",
    "        encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr = learning_rate_encoder, weight_decay = 1e-14)\n",
    "        criterion_encoder = ContrastLoss(latent_dim, margin=margin, replay_const=replay_const)\n",
    "        for task in range(total_task):\n",
    "            print('Doing %d slot, %d shift, %d task'% (slot+1, shift+1, task+1) )\n",
    "            \n",
    "            idx_task = range(task * 5000\\\n",
    "                + slot * num_points_per_task, task * 5000\\\n",
    "                + (slot + 1) * num_points_per_task)\n",
    "\n",
    "            X, y = train_x[idx_task], train_y[idx_task]\n",
    "            y = y.reshape(-1,1)\n",
    "            \n",
    "            train_loader = DataLoader(TaskDataset(X, y), batch_size=batch_size, shuffle=True) \n",
    "\n",
    "            if task == 0:\n",
    "                X_replay = X\n",
    "            else:\n",
    "                X_replay = torch.cat((X_replay, X))\n",
    "            \n",
    "            \n",
    "                with torch.no_grad():\n",
    "                    embedding = encoder(X.float())\n",
    "                    \n",
    "                    for jj in range(total_task_seen):\n",
    "                        head_predicted_label = heads[jj](embedding).argmax(1).view(-1,1)\n",
    "                        y = torch.cat((y, head_predicted_label),\n",
    "                                    dim=1)\n",
    "        \n",
    "            \n",
    "            #######################\n",
    "            if task == 0:\n",
    "                y_replay = y\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    embedding = encoder(X_replay.float())\n",
    "                    \n",
    "                    for jj in range(total_task_seen):\n",
    "                        head_predicted_label = heads[jj](embedding).argmax(1).view(-1,1)\n",
    "            \n",
    "                        if jj == 0:\n",
    "                            y_replay = head_predicted_label\n",
    "                        else:\n",
    "                            y_replay = torch.cat((y_replay, head_predicted_label),dim=1)\n",
    "\n",
    "            replay_loader = DataLoader(TaskDataset(X_replay, y_replay), batch_size=batch_size, shuffle=True) \n",
    "\n",
    "\n",
    "            for epoch in range(epoch_per_task_encoder):\n",
    "                running_loss = 0.0\n",
    "        \n",
    "                count = 0\n",
    "                for (X__, y__), (X_r, y_r) in zip(train_loader, replay_loader):\n",
    "                    encoder_optimizer.zero_grad()\n",
    "                    embedding = encoder(X__.float())\n",
    "                    embedding_replay = encoder(X_r.float())\n",
    "                    \n",
    "                    loss = criterion_encoder(embedding, y__, embedding_replay, y_r)\n",
    "                    #print(X_r.shape)\n",
    "                    loss.backward()\n",
    "                    encoder_optimizer.step()\n",
    "        \n",
    "                    running_loss += loss.item()\n",
    "                    count += 1\n",
    "        \n",
    "            print(\"Epoch :\", epoch+1, \"loss :\", running_loss/(count+1))\n",
    "                    \n",
    "        \n",
    "            ## train head ##\n",
    "            heads[task] = Head(latent_dim=latent_dim, output=classes_per_task)\n",
    "            head_optimizer = torch.optim.SGD(heads[task].parameters(), lr=learning_rate_head, momentum=0.9)\n",
    "            criterion_head = nn.CrossEntropyLoss()\n",
    "                \n",
    "            for epoch in range(epoch_per_task_head):\n",
    "                for X__, y__ in train_loader:\n",
    "                    head_optimizer.zero_grad()\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        embedding = encoder(X__.float())\n",
    "        \n",
    "                    predicted_y = heads[task](embedding)\n",
    "                    loss_head = criterion_head(predicted_y, y__[:,0].long())\n",
    "                    loss_head.backward()\n",
    "                    head_optimizer.step()\n",
    "                    \n",
    "            print(f'head {task+1} Epoch : {epoch+1}, loss: {loss_head:.4f}')\n",
    "\n",
    "            total_task_seen += 1\n",
    "\n",
    "            acc = []\n",
    "            for kk in range(total_task_seen):\n",
    "                idx_test = range(kk * 1000, (kk + 1) * 1000)\n",
    "                x_t, y_t = test_x[idx_test], test_y[idx_test]\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    embedding = encoder(x_t)\n",
    "                    head_predicted_label = heads[kk](embedding).argmax(1).view(-1,1)\n",
    "    \n",
    "                accuracy = torch.sum(y_t.view(-1,1)==head_predicted_label)/10000\n",
    "                print(f'Task {kk+1} accuracy: ', accuracy)\n",
    "                acc.append(accuracy)\n",
    "            \n",
    "            accuracy_multitask.append(acc)\n",
    "\n",
    "\n",
    "        #######################################\n",
    "        for task in range(total_task):\n",
    "            print('Doing %d slot, %d shift, %d single task'% (slot+1, shift+1, task+1) )\n",
    "\n",
    "            encoder = Encoder(latent_dim=latent_dim)\n",
    "            encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr = learning_rate_encoder, weight_decay = 1e-14)\n",
    "            criterion_encoder = ContrastLoss(latent_dim, margin=margin, replay_const=replay_const)\n",
    "        \n",
    "            idx_task = range(task * 5000\\\n",
    "                + slot * num_points_per_task, task * 5000\\\n",
    "                + (slot + 1) * num_points_per_task)\n",
    "\n",
    "            X, y = train_x[idx_task], train_y[idx_task]\n",
    "            y = y.reshape(-1,1)\n",
    "            \n",
    "            train_loader = DataLoader(TaskDataset(X, y), batch_size=batch_size, shuffle=True) \n",
    "\n",
    "            X_replay = X\n",
    "            y_replay = y\n",
    "\n",
    "            replay_loader = DataLoader(TaskDataset(X_replay, y_replay), batch_size=batch_size, shuffle=True) \n",
    "\n",
    "\n",
    "            for epoch in range(epoch_per_task_encoder):\n",
    "                running_loss = 0.0\n",
    "        \n",
    "                count = 0\n",
    "                for (X__, y__), (X_r, y_r) in zip(train_loader, replay_loader):\n",
    "                    encoder_optimizer.zero_grad()\n",
    "                    embedding = encoder(X__.float())\n",
    "                    embedding_replay = encoder(X_r.float())\n",
    "                    \n",
    "                    loss = criterion_encoder(embedding, y__, embedding_replay, y_r)\n",
    "                    #print(X_r.shape)\n",
    "                    loss.backward()\n",
    "                    encoder_optimizer.step()\n",
    "        \n",
    "                    running_loss += loss.item()\n",
    "                    count += 1\n",
    "        \n",
    "            print(\"Epoch :\", epoch+1, \"loss :\", running_loss/(count+1))\n",
    "                    \n",
    "        \n",
    "            ## train head ##\n",
    "            heads_single[task] = Head(latent_dim=latent_dim, output=classes_per_task)\n",
    "            head_optimizer = torch.optim.SGD(heads_single[task].parameters(), lr=learning_rate_head, momentum=0.9)\n",
    "            criterion_head = nn.CrossEntropyLoss()\n",
    "                \n",
    "            for epoch in range(epoch_per_task_head):\n",
    "                for X__, y__ in train_loader:\n",
    "                    head_optimizer.zero_grad()\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        embedding = encoder(X__.float())\n",
    "        \n",
    "                    predicted_y = heads_single[task](embedding)\n",
    "                    loss_head = criterion_head(predicted_y, y__[:,0].long())\n",
    "                    loss_head.backward()\n",
    "                    head_optimizer.step()\n",
    "                    \n",
    "            print(f'head {task+1} Epoch : {epoch+1}, loss: {loss_head:.4f}')\n",
    "\n",
    "\n",
    "            idx_test = range(task * 1000, (task + 1) * 1000)\n",
    "            x_t, y_t = test_x[idx_test], test_y[idx_test]\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                embedding = encoder(x_t)\n",
    "                head_predicted_label = heads_single[task](embedding).argmax(1).view(-1,1)\n",
    "    \n",
    "            accuracy = torch.sum(y_t.view(-1,1)==head_predicted_label)/10000\n",
    "            print(f'Task {task+1} single task accuracy: ', accuracy)\n",
    "    \n",
    "            single_accuracies.append(accuracy)\n",
    "        \n",
    "        #####\n",
    "        summary = (accuracy_multitask, single_accuracies)\n",
    "        \n",
    "        with open('result/ConL'+ \"_\"+ str(shift)+ \"_\"+ str(slot)+ \".pickle\"', 'wb') as f:\n",
    "            pickle.dump(summary, f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "71ec1ffe-d024-48a0-bf32-3e5a72f259f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6190494298934937"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "380c2b9b-5c09-4220-8bda-99c5bdb202f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3, 32, 32)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0704d376-a5a1-40e2-8bdd-bd8ccb3e2905",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
